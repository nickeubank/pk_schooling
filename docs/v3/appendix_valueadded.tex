\documentclass[Eubank_pk_ethnic_sorting.tex]{subfiles}


\begin{document}

The lagged-value-added model incorporates the assumption that current knowledge is an additive function of all current and past inputs and an i.i.d. stochastic error term. This can be written formally as:

\begin{eqnarray}
	Y_{i,t}=\alpha_tX_{i,t}+\alpha_{t-1}X_{i,t-1}+ \dots + \alpha_1X_{i,1} + \epsilon_{i,t}
\end{eqnarray}

where $Y_{i,t}$ is child $i$'s test scores at time $t$ and $X_{t,i}$ is a vector of child, school, and village controls at time $t$. As data on past inputs are usually unavailable, however, they are generally subsumed into a lagged dependent variable included as a control. In this case the lagged-value-added model can be re-written as:

\begin{eqnarray}
	Y_{i,t}=X_{i,t}\alpha+Y_{i,t-1}\beta + \epsilon_{i,t}\label{appendix_primary}
\end{eqnarray}

Where $Y_{i,t-1}$ is assumed to capture all past inputs and unobservable heterogeneity across students. The specification given by Equation~\ref{appendix_primary} is the model primarily employed in this paper. As the interest of this analysis is on the difference between government and private school students, primary interest is on a dummy for school type included in the vector of controls $X_{i,t}$.

Three aspects of this specification are worth emphasizing. First, while the inclusion of a lagged dependent variable effectively controls for unobserved differences that affect differences in test \emph{levels}, it cannot control for unobserved heterogeneity that affects learning \emph{rates}. It is for this reason that while superior to other available methods, value-added analyses can not fully overcome selection issues.\footnote{Some analysis have turned to second-differencing the data and focusing on students who change schools \citep{Andrabi:2011hl}, but these analyses have their own limitations, among them limited sample sizes (given that changes between types of school are relatively infrequent in most surveys) and the assumption that school changes are not the result of some unobserved shock (i.e. that school switches are not accompanied by contemporaneous with other changes -- a potentially problematic assumption given the relative infrequency with which students change schools).}

Second, the $\beta$ term can be interpreted as the ``persistence parameter'' in that it estimates the degree to which past learning may carry forward. A value of one is equivalent to assuming that children do not forget past lessons, while a value of zero corresponds to students forgetting all past lessons each year. While imposing a persistence parameter of one may seem reasonable -- it amounts to regressing the difference in test scores between time $t$ and time $t-1$ on controls -- a growing literature has shown that the test score gains of short term interventions often ``die out'' over time, suggesting that not all that is learned is retained \citep{Banerjee:2007wx, Glewwe:2010hj,Currie:1995wo, Rothstein:2010bk}. \cite{Andrabi:2011hl} shows that imposing the restriction that $\beta=1$ biases learning estimates.

Finally, lagged test scores are generally measured with error, which leads to an often significant attenuation bias in the estimate of $\beta$ and biased estimates of other coefficients \citep{Kane:2002if,Chay:2005wu,Andrabi:2011hl}. Thus keeping with best practices, lagged test scores from all three subjects -- English, Urdu, and math -- are included in all specifications to instruments for the primary lagged test score of interest.

Note further that all child-level results are presented using heteroskedastic-robust standard errors clustered at the level of the village.

\subsection{Village-Level Estimates}\label{}

In addition to estimating learning differences at the level of the child, the primary analysis of this paper is also estimated at the level of the village. To do so, Specification~\ref{primary} is augmented with with fixed effects for each village-school type combination, as below:

\begin{eqnarray*}
	Y_{i,t}=X_{i,t}\alpha+Y_{i,t-1}\beta + \mathbb{I}_{i,j,type,t}\gamma_{j, type}+\epsilon_{i,t}
\end{eqnarray*}

Where $\mathbb{I}_{j, type}$ is a vector of dummies for the village $j$ of child $i$ in school type $type \in \{private, government\}$ at time $t$. The difference between the village private-school dummy coefficients and the village government-school dummy coefficients are then extracted as a village-level estimate of the government-private test score gap. These village-level gaps are then regressed against a series of village-level controls, include village fractionalization, wealth, size, land fractionalization, and adult literacy variables $Z_{j}$ reported at the level of the village $j$, as below:

\begin{eqnarray*}
	Gap_{j}=Z_{j}\delta+\eta_{j}\label{villagespecification}
\end{eqnarray*}

\subsubsection{Teacher-Value Added Estimates}\label{}
A similar method is employed when estimating the contribution of individual teachers to child learning. Specification~\ref{primary} is again employed with the addition of fixed effects for each individual teacher, as below:
\begin{eqnarray*}
	Y_{i,t}=X_{i,t}\alpha+Y_{i,t-1}\beta + \mathbb{I}_{i,k,t}\zeta_{k}+\epsilon_{i,t}\label{teacherspecification}
\end{eqnarray*}

where $\mathbb{I}_{k}$ is a vector of dummies for whether student $i$ was taught by teacher $k$ in year $t$. The fixed effect coefficients $\zeta_{k}$ are then extracted as an estimate of teacher $k$'s contribution to student learning in various results. Teacher results are all weighted by the number of students taught by a given teacher, both because our interest is in the experience of the average child and because value-added estimates for teachers with small classes are extremely imprecise and are otherwise prone to skew results. 

% section data (end)

\end{document}
